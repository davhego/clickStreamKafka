from confluent_kafka import Consumer, KafkaError
from azure.storage.blob import BlobServiceClient

# Configura el consumidor de Kafka
consumer = Consumer({
    'bootstrap.servers': 'localhost:9092',  # Reemplaza con la dirección de tu servidor Kafka
    'group.id': 'clickstream-group',  # Reemplaza con el ID de tu grupo de consumidores
    'auto.offset.reset': 'earliest'  # Cambia a 'latest' si solo quieres los mensajes nuevos
})

consumer.subscribe(['clickstream-topic'])  # Reemplaza con el nombre de tu topic

# Configura el cliente de Azure Blob Storage
blob_service_client = BlobServiceClient.from_connection_string('DefaultEndpointsProtocol=https;AccountName=espacio2;AccountKey=yDTeT0HDDthr9WSBh9E8vbFqDq1Md6zUiXjs1me5o0xbXlrQoSnmKxjKU6iWqVrxEW1liTz3UJ1x+AStTN9Nzw==;EndpointSuffix=core.windows.net')  # la cadena de conexión
container_client = blob_service_client.get_container_client('contenido23')  # nombre del contenedor

while True:
    msg = consumer.poll(1.0)

    if msg is None:
        continue
    if msg.error():
        if msg.error().code() == KafkaError._PARTITION_EOF:
            continue
        else:
            print(msg.error())
            break

    # Verifica si la clave y el valor no son None antes de decodificar
    key = msg.key()
    value = msg.value()

    if key is not None:
        key_str = key.decode('utf-8')
    else:
        key_str = 'unknown_key3'  # O alguna otra estrategia para manejar claves None

    if value is not None:
        value_str = value.decode('utf-8')
    else:
        print("Error: El valor del mensaje es None")
        continue  # O maneja el caso como consideres adecuado

    # Procesa y almacena el mensaje en el Data Lake
    blob_name = f"bronze/clickstream/{key_str}.json"
    blob_client = container_client.get_blob_client(blob_name)
    blob_client.upload_blob(value_str)

consumer.close()